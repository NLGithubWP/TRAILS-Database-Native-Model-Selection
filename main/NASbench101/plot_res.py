
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scipy.stats as stats


def get_index_after_sort(s):
    res = sorted(range(len(s)), key=lambda k: s[k])
    return res


def get_overlap(a, b):
    inter = list(set(a) & set(b))
    percent = len(inter) / len(a)
    return percent


score = [24.350677,58.967995,9.581612,29.906538,2.9943695,2.4384172,57.465942,10.84382,2.782402,74.004425,33.4178,12.9562235,57.58215,9.144171,10.831597,54.706715,16.865223,8.604723,1.5060569,13.437509,8.52165,-25.515701,10.77968,39.46517,64.06886,12.035192,8.504285,5.8644123,33.53266,57.01982,1.1174233,71.16912,78.47406,20.529486,9.738795,11.90801,1.2958462,24.63704,-234.19388,-435.05432,27.56036,11.040428,16.517315,-639.9745,21.674864,1.7024,12.485797,9.532228,-48.229538,8.367806,80.78327,97.55742,28.244553,13.134044,26.29515,10.030296,8.287116,87.40683,15.017804,15.927257,12.783486,63.274944,1.2131048,72.5576,28.733923,22.914778,92.56838,12.014963,7.551647,14.810396,37.82625,45.02623,34.081936,82.13082,15.513284,95.62825,59.645782,21.385574,23.506496,15.490117,15.483295,10.360325,41.98701,8.821427,84.61559,25.448738,13.724832,35.103626,2.3843877,56.69364,26.839647,17.29913,72.24606,19.544073,17.73619,54.958904,89.53305,16.347012,94.924194,1.8908986,67.25559,9.229064,20.794033,39.931747,72.52457,9.365928,26.488646,12.144062,32.950584,46.545258,91.45344,45.551575,1.832341,45.587402,35.1841,73.37102,46.424984,30.018492,-310.0602,19.708876,2.6377401,10.57994,10.231076,11.184054,27.102324,-21.48854,15.12383,23.504143,2.3083615,9.208817,9.78536,1.7740357,9.689192,10.675232,47.83811,8.658291,77.91761,38.60114,50.107822,25.107872,1.809185,9.63101,29.477348,56.85521,68.650696,25.187912,13.19739,12.562046,27.898693,27.206497,11.926527,65.03511,82.86781,27.462854,29.45403,8.50604,1.6509292,-92.973785,69.202156,10.75547,72.7347,17.394274,24.196016,7.2501497,1.6570706,8.041287,5.184644,19.693815]
train_accuracy = [1.0, 0.9998998641967773, 0.9428085088729858, 0.9998998641967773, 0.9993990659713745, 0.9769631624221802, 1.0, 0.9848757982254028, 0.9769631624221802, 1.0, 1.0, 0.9322916865348816, 1.0, 1.0, 1.0, 0.9997996687889099, 1.0, 0.9383012652397156, 0.9788661599159241, 1.0, 0.9383012652397156, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9378004670143127, 1.0, 0.9998998641967773, 1.0, 0.9769631624221802, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9789663553237915, 1.0, 1.0, 0.9974960088729858, 1.0, 1.0, 0.9320913553237915, 1.0, 1.0, 0.9789663553237915, 1.0, 1.0, 0.8583734035491943, 0.9322916865348816, 0.9998998641967773, 0.9996995329856873, 0.9357972741127014, 1.0, 0.9997996687889099, 1.0, 0.9906851053237915, 1.0, 1.0, 1.0, 0.9835737347602844, 0.9998998641967773, 0.9789663553237915, 0.8308293223381042, 1.0, 1.0, 0.9992988705635071, 1.0, 0.9998998641967773, 1.0, 0.9998998641967773, 1.0, 1.0, 0.9997996687889099, 1.0, 1.0, 1.0, 0.9997996687889099, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9998998641967773, 0.8636819124221802, 1.0, 1.0, 0.9788661599159241, 1.0, 0.9998998641967773, 1.0, 0.9994992017745972, 1.0, 0.9761618375778198, 0.9998998641967773, 0.9998998641967773, 1.0, 1.0, 0.9769631624221802, 1.0, 0.9322916865348816, 1.0, 1.0, 0.9996995329856873, 1.0, 1.0, 0.9320913553237915, 0.9998998641967773, 0.9939903616905212, 1.0, 1.0, 0.9788661599159241, 1.0, 1.0, 1.0, 0.9998998641967773, 1.0, 1.0, 0.9998998641967773, 0.9788661599159241, 1.0, 1.0, 1.0, 1.0, 0.9998998641967773, 1.0, 1.0, 0.9789663553237915, 0.9816706776618958, 1.0, 0.9769631624221802, 1.0, 1.0, 1.0, 0.9322916865348816, 0.9997996687889099, 0.9998998641967773, 1.0, 0.9998998641967773, 0.9788661599159241, 1.0, 1.0, 0.9998998641967773, 0.9998998641967773, 0.9998998641967773, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9991987347602844, 0.9996995329856873, 1.0, 0.9995993375778198, 1.0, 0.9769631624221802, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9383012652397156, 0.9788661599159241, 1.0, 0.9878805875778198, 1.0]
validation_accuracy = [0.8950320482254028, 0.8974359035491943, 0.8268229365348816, 0.9278846383094788, 0.9051482081413269, 0.8346354365348816, 0.9159655570983887, 0.8360376358032227, 0.8346354365348816, 0.8793069124221802, 0.9060496687889099, 0.8224158883094788, 0.9261819124221802, 0.9360977411270142, 0.8958333134651184, 0.8910256624221802, 0.9206730723381042, 0.8270232081413269, 0.8358373641967773, 0.9331930875778198, 0.8270232081413269, 0.9118589758872986, 0.8939303159713745, 0.8859174847602844, 0.917067289352417, 0.9334936141967773, 0.8240184187889099, 0.9429086446762085, 0.9298878312110901, 0.9274839758872986, 0.8346354365348816, 0.9254807829856873, 0.9246794581413269, 0.8791065812110901, 0.9404046535491943, 0.8939303159713745, 0.8316305875778198, 0.9025440812110901, 0.9381009340286255, 0.8695913553237915, 0.9249799847602844, 0.9379006624221802, 0.8200120329856873, 0.9320913553237915, 0.9366987347602844, 0.8316305875778198, 0.8939303159713745, 0.8939303159713745, 0.7861578464508057, 0.8224158883094788, 0.9142628312110901, 0.88671875, 0.8168069124221802, 0.9311898946762085, 0.9399038553237915, 0.8939303159713745, 0.8371394276618958, 0.9201722741127014, 0.885817289352417, 0.932692289352417, 0.8385416865348816, 0.8862179517745972, 0.8316305875778198, 0.7720352411270142, 0.8950320482254028, 0.9025440812110901, 0.8812099099159241, 0.9351963400840759, 0.9311898946762085, 0.9407051205635071, 0.9125601053237915, 0.9270833134651184, 0.909254789352417, 0.9201722741127014, 0.8800080418586731, 0.9260817170143127, 0.8846153616905212, 0.9011418223381042, 0.8868188858032227, 0.9312900900840759, 0.885817289352417, 0.8939303159713745, 0.9176682829856873, 0.9351963400840759, 0.8952323794364929, 0.7963742017745972, 0.8938301205635071, 0.9346955418586731, 0.8358373641967773, 0.9311898946762085, 0.9292868375778198, 0.8853164911270142, 0.8755007982254028, 0.905348539352417, 0.8466546535491943, 0.8886218070983887, 0.8813101053237915, 0.9332932829856873, 0.9154647588729858, 0.8346354365348816, 0.9246794581413269, 0.8224158883094788, 0.8827123641967773, 0.9125601053237915, 0.8888221383094788, 0.885817289352417, 0.9391025900840759, 0.8200120329856873, 0.8984375, 0.8474559187889099, 0.8855168223381042, 0.9336938858032227, 0.8358373641967773, 0.934495210647583, 0.8773036599159241, 0.9268830418586731, 0.9234775900840759, 0.9276843070983887, 0.9202724099159241, 0.8825120329856873, 0.8358373641967773, 0.8958333134651184, 0.9247796535491943, 0.885817289352417, 0.9044471383094788, 0.889723539352417, 0.9332932829856873, 0.8950320482254028, 0.8316305875778198, 0.836838960647583, 0.9367988705635071, 0.8346354365348816, 0.9360977411270142, 0.8939303159713745, 0.913161039352417, 0.8224158883094788, 0.91015625, 0.89453125, 0.9163661599159241, 0.9255809187889099, 0.8358373641967773, 0.885817289352417, 0.8950320482254028, 0.9281851053237915, 0.9294871687889099, 0.8900240659713745, 0.9312900900840759, 0.9368990659713745, 0.9012419581413269, 0.9338942170143127, 0.8890224099159241, 0.8827123641967773, 0.8836137652397156, 0.9338942170143127, 0.8698918223381042, 0.9360977411270142, 0.8346354365348816, 0.9242788553237915, 0.9304887652397156, 0.8958333134651184, 0.8893229365348816, 0.9331930875778198, 0.8901242017745972, 0.8270232081413269, 0.8358373641967773, 0.9307892918586731, 0.8339343070983887, 0.8925280570983887]
test_accuracy = [0.8892227411270142, 0.8955328464508057, 0.8247195482254028, 0.9210737347602844, 0.9046474099159241, 0.8361378312110901, 0.9107571840286255, 0.8334335088729858, 0.8361378312110901, 0.8721955418586731, 0.8991386294364929, 0.8183093070983887, 0.9187700152397156, 0.9319911599159241, 0.8893229365348816, 0.8816105723381042, 0.9143629670143127, 0.8246194124221802, 0.8410456776618958, 0.9280849099159241, 0.8246194124221802, 0.9089543223381042, 0.8863180875778198, 0.8806089758872986, 0.9140625, 0.928786039352417, 0.8205128312110901, 0.9371995329856873, 0.9230769276618958, 0.9178686141967773, 0.8361378312110901, 0.9201722741127014, 0.9219751358032227, 0.8825120329856873, 0.9329928159713745, 0.8863180875778198, 0.8359375, 0.9027444124221802, 0.9332932829856873, 0.8692908883094788, 0.9230769276618958, 0.9334936141967773, 0.8185096383094788, 0.922776460647583, 0.9331930875778198, 0.8359375, 0.8863180875778198, 0.8863180875778198, 0.7916666865348816, 0.8183093070983887, 0.9116586446762085, 0.88671875, 0.8147035241127014, 0.9208734035491943, 0.9338942170143127, 0.8863180875778198, 0.8384414911270142, 0.9133613705635071, 0.8829126358032227, 0.9303886294364929, 0.8347355723381042, 0.881911039352417, 0.8359375, 0.7691305875778198, 0.8892227411270142, 0.8930288553237915, 0.8737980723381042, 0.9303886294364929, 0.9233773946762085, 0.9386017918586731, 0.9041466116905212, 0.9213742017745972, 0.9005408883094788, 0.9095553159713745, 0.8738982081413269, 0.9243789911270142, 0.881911039352417, 0.893629789352417, 0.8820112347602844, 0.922776460647583, 0.8829126358032227, 0.8863180875778198, 0.9132612347602844, 0.9294871687889099, 0.889723539352417, 0.7900640964508057, 0.8898237347602844, 0.9288862347602844, 0.8410456776618958, 0.9241786599159241, 0.9272836446762085, 0.8821113705635071, 0.8730969429016113, 0.8983373641967773, 0.8374398946762085, 0.881911039352417, 0.8771033883094788, 0.9264823794364929, 0.9104567170143127, 0.8361378312110901, 0.9237780570983887, 0.8183093070983887, 0.8844150900840759, 0.9026442170143127, 0.8885216116905212, 0.8829126358032227, 0.9296875, 0.8185096383094788, 0.8909254670143127, 0.8478565812110901, 0.8813101053237915, 0.9292868375778198, 0.8410456776618958, 0.9284855723381042, 0.8795071840286255, 0.9223757982254028, 0.9221754670143127, 0.9244791865348816, 0.9176682829856873, 0.8774038553237915, 0.8410456776618958, 0.8893229365348816, 0.9203726053237915, 0.8829126358032227, 0.901442289352417, 0.8848156929016113, 0.9276843070983887, 0.8892227411270142, 0.8359375, 0.8366386294364929, 0.9292868375778198, 0.8361378312110901, 0.9319911599159241, 0.8863180875778198, 0.9090544581413269, 0.8183093070983887, 0.9039463400840759, 0.8852163553237915, 0.9118589758872986, 0.9212740659713745, 0.8410456776618958, 0.8829126358032227, 0.8892227411270142, 0.9165664911270142, 0.9261819124221802, 0.8862179517745972, 0.9246794581413269, 0.9312900900840759, 0.8951321840286255, 0.9288862347602844, 0.8881210088729858, 0.8748998641967773, 0.881911039352417, 0.9267828464508057, 0.8691906929016113, 0.9319911599159241, 0.8361378312110901, 0.9165664911270142, 0.9253805875778198, 0.8893229365348816, 0.8888221383094788, 0.9280849099159241, 0.8861178159713745, 0.8246194124221802, 0.8410456776618958, 0.922776460647583, 0.835036039352417, 0.8902243375778198]

x = range(1, len(test_accuracy)+1)

r = stats.pearsonr(score, validation_accuracy)
print("corr = ", r)

score_index = get_index_after_sort(score)
validation_accuracy_index = get_index_after_sort(validation_accuracy)

# get the overlap of the top 100,10, 30
print("Top100 overlap = ", get_overlap(score_index[-100:], validation_accuracy_index[-100:]))
print("Top10 overlap = ", get_overlap(score_index[-10:], validation_accuracy_index[-10:]))
print("Top20 overlap = ", get_overlap(score_index[-20:], validation_accuracy_index[-20:]))
print("Top30 overlap = ", get_overlap(score_index[-30:], validation_accuracy_index[-30:]))
print("Top50 overlap = ", get_overlap(score_index[-50:], validation_accuracy_index[-50:]))
print("Top100 overlap = ", get_overlap(score_index[-100:], validation_accuracy_index[-100:]))


# plot lines
plt.plot(x, score, label = "score")
plt.plot(x, [ele*100 for ele in train_accuracy], label = "train_accuracy")
plt.plot(x, [ele*100 for ele in validation_accuracy], label = "validation_accuracy")
plt.plot(x, [ele*100 for ele in test_accuracy], label = "test_accuracy")
plt.legend()
plt.show()

